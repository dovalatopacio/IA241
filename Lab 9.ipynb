{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import tweepy\n",
    "import twitter\n",
    "from pprint import pprint\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config2.ini')\n",
    "\n",
    "CONSUMER_KEY      = config['mytwitter']['api_key']\n",
    "CONSUMER_SECRET   = config['mytwitter']['api_secrete']\n",
    "OAUTH_TOKEN       = config['mytwitter']['access_token']\n",
    "OATH_TOKEN_SECRET = config['mytwitter']['access_secrete']\n",
    "\n",
    "mongod_connect = config['mymongo']['connection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id_1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(mongod_connect)\n",
    "db = client.tweet_db # create a database named tweet_db\n",
    "tweet_collection = db.tweet_collection_job #create a collection called tweet_collection\n",
    "tweet_collection.create_index([(\"id\", pymongo.ASCENDING)],unique = True) # make sure the collected tweets are uniqueb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dnspython in c:\\programdata\\anaconda3\\lib\\site-packages (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install dnspython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "stream_auth.set_access_token(OAUTH_TOKEN, OATH_TOKEN_SECRET)\n",
    "\n",
    "strem_api = tweepy.API(stream_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = ['ia jobs'] # define the keywords, tweets contain IA Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def on_status(self, status):\n",
    "        print (status.id_str)\n",
    "        try:\n",
    "            tweet_collection.insert_one(status._json)\n",
    "        except:\n",
    "            pass\n",
    "  \n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            #returning False in on_data disconnects the stream\n",
    "            return False\n",
    "myStreamListener = MyStreamListener()\n",
    "myStream = tweepy.Stream(auth = strem_api.auth, listener=myStreamListener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_auth = twitter.oauth.OAuth(OAUTH_TOKEN,OATH_TOKEN_SECRET,CONSUMER_KEY,CONSUMER_SECRET)\n",
    "rest_api = twitter.Twitter(auth=rest_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 100 #number of returned tweets, default and max is 100\n",
    "# geocode = \"38.9072,-77.0369,50mi\"  # defin the location\n",
    "q = \"ia job\"                               #define the keywords, tweets contain IA Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Tue Nov 05 19:56:34 +0000 2019'\n",
      "'Tue Nov 05 19:55:54 +0000 2019'\n",
      "'Tue Nov 05 19:55:13 +0000 2019'\n",
      "'Tue Nov 05 19:54:54 +0000 2019'\n",
      "'Tue Nov 05 19:54:43 +0000 2019'\n",
      "'Tue Nov 05 19:50:34 +0000 2019'\n",
      "'Tue Nov 05 19:50:24 +0000 2019'\n",
      "'Tue Nov 05 19:49:57 +0000 2019'\n",
      "'Tue Nov 05 19:48:43 +0000 2019'\n",
      "'Tue Nov 05 19:46:52 +0000 2019'\n",
      "'Tue Nov 05 19:46:43 +0000 2019'\n",
      "'Tue Nov 05 19:46:18 +0000 2019'\n",
      "'Tue Nov 05 19:45:33 +0000 2019'\n",
      "'Tue Nov 05 19:45:13 +0000 2019'\n",
      "'Tue Nov 05 19:44:52 +0000 2019'\n",
      "'Tue Nov 05 19:44:23 +0000 2019'\n",
      "'Tue Nov 05 19:42:21 +0000 2019'\n",
      "'Tue Nov 05 19:39:12 +0000 2019'\n",
      "'Tue Nov 05 19:38:32 +0000 2019'\n",
      "'Tue Nov 05 19:37:22 +0000 2019'\n",
      "'Tue Nov 05 19:30:41 +0000 2019'\n",
      "'Tue Nov 05 19:29:21 +0000 2019'\n",
      "'Tue Nov 05 19:28:53 +0000 2019'\n",
      "'Tue Nov 05 19:28:22 +0000 2019'\n",
      "'Tue Nov 05 19:27:20 +0000 2019'\n",
      "'Tue Nov 05 19:25:30 +0000 2019'\n",
      "'Tue Nov 05 19:24:02 +0000 2019'\n",
      "'Tue Nov 05 19:20:40 +0000 2019'\n",
      "'Tue Nov 05 19:19:50 +0000 2019'\n",
      "'Tue Nov 05 19:16:30 +0000 2019'\n",
      "'Tue Nov 05 19:15:39 +0000 2019'\n",
      "'Tue Nov 05 19:12:11 +0000 2019'\n",
      "'Tue Nov 05 19:10:39 +0000 2019'\n",
      "'Tue Nov 05 19:08:09 +0000 2019'\n",
      "'Tue Nov 05 19:07:29 +0000 2019'\n",
      "'Tue Nov 05 19:07:19 +0000 2019'\n",
      "'Tue Nov 05 19:05:29 +0000 2019'\n",
      "'Tue Nov 05 19:03:28 +0000 2019'\n",
      "'Tue Nov 05 19:02:52 +0000 2019'\n",
      "'Tue Nov 05 19:00:28 +0000 2019'\n",
      "'Tue Nov 05 18:49:17 +0000 2019'\n",
      "'Tue Nov 05 18:48:27 +0000 2019'\n",
      "'Tue Nov 05 18:47:47 +0000 2019'\n",
      "'Tue Nov 05 18:47:27 +0000 2019'\n",
      "'Tue Nov 05 18:45:26 +0000 2019'\n",
      "'Tue Nov 05 18:44:38 +0000 2019'\n",
      "'Tue Nov 05 18:43:26 +0000 2019'\n",
      "'Tue Nov 05 18:38:18 +0000 2019'\n",
      "'Tue Nov 05 18:37:55 +0000 2019'\n",
      "'Tue Nov 05 18:37:15 +0000 2019'\n",
      "'Tue Nov 05 18:31:15 +0000 2019'\n",
      "'Tue Nov 05 18:27:54 +0000 2019'\n",
      "'Tue Nov 05 18:23:44 +0000 2019'\n",
      "'Tue Nov 05 18:21:05 +0000 2019'\n",
      "'Tue Nov 05 18:20:46 +0000 2019'\n",
      "'Tue Nov 05 18:19:53 +0000 2019'\n",
      "'Tue Nov 05 18:18:14 +0000 2019'\n",
      "'Tue Nov 05 18:17:55 +0000 2019'\n",
      "'Tue Nov 05 18:16:25 +0000 2019'\n",
      "'Tue Nov 05 18:14:00 +0000 2019'\n",
      "'Tue Nov 05 18:11:10 +0000 2019'\n",
      "'Tue Nov 05 18:09:13 +0000 2019'\n",
      "'Tue Nov 05 18:07:43 +0000 2019'\n",
      "'Tue Nov 05 18:06:32 +0000 2019'\n",
      "'Tue Nov 05 18:05:04 +0000 2019'\n",
      "'Tue Nov 05 18:04:34 +0000 2019'\n",
      "'Tue Nov 05 18:03:12 +0000 2019'\n",
      "'Tue Nov 05 18:02:02 +0000 2019'\n",
      "'Tue Nov 05 18:01:03 +0000 2019'\n",
      "'Tue Nov 05 18:01:01 +0000 2019'\n",
      "'Tue Nov 05 17:55:11 +0000 2019'\n",
      "'Tue Nov 05 17:53:33 +0000 2019'\n",
      "'Tue Nov 05 17:53:20 +0000 2019'\n",
      "'Tue Nov 05 17:45:09 +0000 2019'\n",
      "'Tue Nov 05 17:41:20 +0000 2019'\n",
      "'Tue Nov 05 17:40:50 +0000 2019'\n",
      "'Tue Nov 05 17:40:32 +0000 2019'\n",
      "'Tue Nov 05 17:39:01 +0000 2019'\n",
      "'Tue Nov 05 17:37:09 +0000 2019'\n",
      "'Tue Nov 05 17:33:08 +0000 2019'\n",
      "'Tue Nov 05 17:31:39 +0000 2019'\n",
      "'Tue Nov 05 17:30:43 +0000 2019'\n",
      "'Tue Nov 05 17:30:40 +0000 2019'\n",
      "'Tue Nov 05 17:30:38 +0000 2019'\n",
      "'Tue Nov 05 17:29:30 +0000 2019'\n",
      "'Tue Nov 05 17:29:11 +0000 2019'\n",
      "'Tue Nov 05 17:27:30 +0000 2019'\n",
      "'Tue Nov 05 17:27:09 +0000 2019'\n",
      "'Tue Nov 05 17:23:18 +0000 2019'\n",
      "'Tue Nov 05 17:20:57 +0000 2019'\n",
      "'Tue Nov 05 17:18:16 +0000 2019'\n",
      "'Tue Nov 05 17:16:57 +0000 2019'\n",
      "'Tue Nov 05 17:16:46 +0000 2019'\n",
      "'Tue Nov 05 17:13:51 +0000 2019'\n",
      "'Tue Nov 05 17:13:06 +0000 2019'\n",
      "'Tue Nov 05 17:10:17 +0000 2019'\n",
      "'Tue Nov 05 17:08:46 +0000 2019'\n",
      "'Tue Nov 05 17:06:47 +0000 2019'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "search_results = rest_api.search.tweets( count=count,q=q)\n",
    "statuses = search_results[\"statuses\"]\n",
    "since_id_new = statuses[-1]['id']\n",
    "for statuse in statuses:\n",
    "    try:\n",
    "        tweet_collection.insert_one(statuse)\n",
    "        pprint(statuse['created_at'])# print the date of the collected tweets\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Mon Oct 28 20:00:08 +0000 2019'\n",
      "'Mon Oct 28 19:55:52 +0000 2019'\n",
      "'Mon Oct 28 19:53:39 +0000 2019'\n",
      "'Mon Oct 28 19:52:07 +0000 2019'\n",
      "'Mon Oct 28 19:50:47 +0000 2019'\n",
      "'Mon Oct 28 19:49:47 +0000 2019'\n",
      "'Mon Oct 28 19:48:27 +0000 2019'\n",
      "'Mon Oct 28 19:45:57 +0000 2019'\n",
      "'Mon Oct 28 19:45:47 +0000 2019'\n",
      "'Mon Oct 28 19:41:40 +0000 2019'\n",
      "'Mon Oct 28 19:41:01 +0000 2019'\n",
      "'Mon Oct 28 19:35:49 +0000 2019'\n",
      "'Mon Oct 28 19:28:35 +0000 2019'\n",
      "'Mon Oct 28 19:27:45 +0000 2019'\n",
      "'Mon Oct 28 19:22:15 +0000 2019'\n",
      "'Mon Oct 28 19:12:16 +0000 2019'\n",
      "'Mon Oct 28 19:11:34 +0000 2019'\n",
      "'Mon Oct 28 19:11:18 +0000 2019'\n",
      "'Mon Oct 28 19:06:33 +0000 2019'\n",
      "'Mon Oct 28 19:06:09 +0000 2019'\n",
      "'Mon Oct 28 18:57:31 +0000 2019'\n",
      "'Mon Oct 28 18:52:22 +0000 2019'\n",
      "'Mon Oct 28 18:46:23 +0000 2019'\n",
      "'Mon Oct 28 18:44:31 +0000 2019'\n",
      "'Mon Oct 28 18:42:01 +0000 2019'\n",
      "'Mon Oct 28 18:39:30 +0000 2019'\n",
      "'Mon Oct 28 18:36:02 +0000 2019'\n",
      "'Mon Oct 28 18:34:00 +0000 2019'\n",
      "'Mon Oct 28 18:20:19 +0000 2019'\n",
      "'Mon Oct 28 18:19:01 +0000 2019'\n",
      "'Mon Oct 28 18:11:22 +0000 2019'\n",
      "'Mon Oct 28 18:09:26 +0000 2019'\n",
      "'Mon Oct 28 18:08:45 +0000 2019'\n",
      "'Mon Oct 28 18:06:09 +0000 2019'\n",
      "'Mon Oct 28 18:05:09 +0000 2019'\n",
      "'Mon Oct 28 18:04:37 +0000 2019'\n",
      "'Mon Oct 28 17:56:48 +0000 2019'\n",
      "'Mon Oct 28 17:55:16 +0000 2019'\n",
      "'Mon Oct 28 17:54:06 +0000 2019'\n",
      "'Mon Oct 28 17:54:05 +0000 2019'\n",
      "'Mon Oct 28 17:54:03 +0000 2019'\n",
      "'Mon Oct 28 17:51:38 +0000 2019'\n",
      "'Mon Oct 28 17:38:48 +0000 2019'\n",
      "'Mon Oct 28 17:37:22 +0000 2019'\n",
      "'Mon Oct 28 17:34:17 +0000 2019'\n",
      "'Mon Oct 28 17:33:54 +0000 2019'\n",
      "'Mon Oct 28 17:30:26 +0000 2019'\n",
      "'Mon Oct 28 17:26:44 +0000 2019'\n",
      "'Mon Oct 28 17:26:34 +0000 2019'\n",
      "'Mon Oct 28 17:24:55 +0000 2019'\n",
      "'Mon Oct 28 17:13:24 +0000 2019'\n",
      "'Mon Oct 28 17:12:56 +0000 2019'\n",
      "'Mon Oct 28 17:12:41 +0000 2019'\n",
      "'Mon Oct 28 17:02:51 +0000 2019'\n",
      "'Mon Oct 28 17:01:51 +0000 2019'\n",
      "'Mon Oct 28 16:58:51 +0000 2019'\n",
      "'Mon Oct 28 16:46:19 +0000 2019'\n",
      "'Mon Oct 28 16:39:41 +0000 2019'\n",
      "'Mon Oct 28 16:39:29 +0000 2019'\n",
      "'Mon Oct 28 16:37:57 +0000 2019'\n",
      "'Mon Oct 28 16:36:29 +0000 2019'\n",
      "'Mon Oct 28 16:34:09 +0000 2019'\n",
      "'Mon Oct 28 16:28:29 +0000 2019'\n",
      "'Mon Oct 28 16:26:29 +0000 2019'\n",
      "'Mon Oct 28 16:22:57 +0000 2019'\n",
      "'Mon Oct 28 16:22:37 +0000 2019'\n",
      "'Mon Oct 28 16:19:27 +0000 2019'\n",
      "'Mon Oct 28 16:06:41 +0000 2019'\n",
      "'Mon Oct 28 16:06:27 +0000 2019'\n",
      "'Mon Oct 28 16:01:45 +0000 2019'\n",
      "'Mon Oct 28 15:56:04 +0000 2019'\n",
      "'Mon Oct 28 15:47:44 +0000 2019'\n",
      "'Mon Oct 28 15:44:14 +0000 2019'\n",
      "'Mon Oct 28 15:43:35 +0000 2019'\n",
      "'Mon Oct 28 15:42:13 +0000 2019'\n",
      "'Mon Oct 28 15:41:33 +0000 2019'\n",
      "'Mon Oct 28 15:37:50 +0000 2019'\n",
      "'Mon Oct 28 15:37:44 +0000 2019'\n",
      "'Mon Oct 28 15:37:43 +0000 2019'\n",
      "'Mon Oct 28 15:36:59 +0000 2019'\n",
      "'Mon Oct 28 15:36:42 +0000 2019'\n",
      "'Mon Oct 28 15:29:28 +0000 2019'\n",
      "'Mon Oct 28 15:27:13 +0000 2019'\n",
      "'Mon Oct 28 15:26:11 +0000 2019'\n",
      "'Mon Oct 28 15:25:53 +0000 2019'\n",
      "'Mon Oct 28 15:25:01 +0000 2019'\n",
      "'Mon Oct 28 15:24:32 +0000 2019'\n",
      "'Mon Oct 28 15:23:13 +0000 2019'\n",
      "'Mon Oct 28 15:23:02 +0000 2019'\n",
      "'Mon Oct 28 15:22:50 +0000 2019'\n",
      "'Mon Oct 28 15:18:18 +0000 2019'\n",
      "'Mon Oct 28 15:18:10 +0000 2019'\n",
      "'Mon Oct 28 15:17:15 +0000 2019'\n",
      "'Mon Oct 28 15:12:11 +0000 2019'\n",
      "'Mon Oct 28 15:12:01 +0000 2019'\n",
      "'Mon Oct 28 15:10:41 +0000 2019'\n",
      "'Mon Oct 28 15:06:17 +0000 2019'\n",
      "'Mon Oct 28 14:59:29 +0000 2019'\n",
      "'Mon Oct 28 14:56:39 +0000 2019'\n",
      "'Mon Oct 28 14:55:59 +0000 2019'\n",
      "'Mon Oct 28 14:41:28 +0000 2019'\n",
      "'Mon Oct 28 14:37:59 +0000 2019'\n",
      "'Mon Oct 28 14:30:04 +0000 2019'\n",
      "'Mon Oct 28 14:26:58 +0000 2019'\n",
      "'Mon Oct 28 14:26:46 +0000 2019'\n",
      "'Mon Oct 28 14:17:38 +0000 2019'\n",
      "'Mon Oct 28 14:16:02 +0000 2019'\n",
      "'Mon Oct 28 14:10:47 +0000 2019'\n",
      "'Mon Oct 28 14:09:29 +0000 2019'\n",
      "'Mon Oct 28 14:08:46 +0000 2019'\n",
      "'Mon Oct 28 14:07:32 +0000 2019'\n",
      "'Mon Oct 28 14:07:09 +0000 2019'\n",
      "'Mon Oct 28 14:04:55 +0000 2019'\n",
      "'Mon Oct 28 14:02:34 +0000 2019'\n",
      "'Mon Oct 28 13:57:55 +0000 2019'\n",
      "'Mon Oct 28 13:45:21 +0000 2019'\n",
      "'Mon Oct 28 13:23:15 +0000 2019'\n",
      "'Mon Oct 28 13:22:44 +0000 2019'\n",
      "'Mon Oct 28 13:20:40 +0000 2019'\n",
      "'Mon Oct 28 13:09:29 +0000 2019'\n",
      "'Mon Oct 28 13:05:02 +0000 2019'\n",
      "'Mon Oct 28 12:59:08 +0000 2019'\n",
      "'Mon Oct 28 12:58:31 +0000 2019'\n",
      "'Mon Oct 28 12:54:02 +0000 2019'\n",
      "'Mon Oct 28 12:51:53 +0000 2019'\n",
      "'Mon Oct 28 12:48:58 +0000 2019'\n",
      "'Mon Oct 28 12:40:32 +0000 2019'\n",
      "'Mon Oct 28 12:32:55 +0000 2019'\n",
      "'Mon Oct 28 12:31:17 +0000 2019'\n",
      "'Mon Oct 28 12:27:41 +0000 2019'\n",
      "'Mon Oct 28 11:48:21 +0000 2019'\n",
      "'Mon Oct 28 11:23:50 +0000 2019'\n",
      "'Mon Oct 28 11:19:00 +0000 2019'\n",
      "'Mon Oct 28 10:41:28 +0000 2019'\n",
      "'Mon Oct 28 10:39:42 +0000 2019'\n",
      "'Mon Oct 28 10:23:29 +0000 2019'\n",
      "'Mon Oct 28 09:24:59 +0000 2019'\n",
      "'Mon Oct 28 06:54:30 +0000 2019'\n",
      "'Mon Oct 28 06:51:25 +0000 2019'\n",
      "'Mon Oct 28 06:50:07 +0000 2019'\n",
      "'Mon Oct 28 06:40:33 +0000 2019'\n",
      "'Mon Oct 28 06:02:08 +0000 2019'\n",
      "'Mon Oct 28 05:43:11 +0000 2019'\n",
      "'Mon Oct 28 05:12:05 +0000 2019'\n",
      "'Mon Oct 28 05:11:15 +0000 2019'\n",
      "'Mon Oct 28 05:10:48 +0000 2019'\n",
      "'Mon Oct 28 04:16:39 +0000 2019'\n",
      "'Mon Oct 28 03:49:10 +0000 2019'\n",
      "'Mon Oct 28 03:10:49 +0000 2019'\n",
      "'Mon Oct 28 03:10:48 +0000 2019'\n",
      "'Mon Oct 28 02:49:41 +0000 2019'\n",
      "'Mon Oct 28 02:40:16 +0000 2019'\n",
      "'Mon Oct 28 02:09:29 +0000 2019'\n",
      "'Mon Oct 28 02:07:06 +0000 2019'\n",
      "'Mon Oct 28 02:01:06 +0000 2019'\n",
      "'Mon Oct 28 01:57:59 +0000 2019'\n",
      "'Mon Oct 28 01:55:35 +0000 2019'\n",
      "'Mon Oct 28 01:39:27 +0000 2019'\n",
      "'Mon Oct 28 01:30:33 +0000 2019'\n",
      "'Mon Oct 28 01:06:09 +0000 2019'\n",
      "'Mon Oct 28 00:52:16 +0000 2019'\n",
      "'Mon Oct 28 00:45:07 +0000 2019'\n",
      "'Mon Oct 28 00:13:07 +0000 2019'\n",
      "'Mon Oct 28 00:10:46 +0000 2019'\n",
      "'Sun Oct 27 23:46:49 +0000 2019'\n",
      "'Sun Oct 27 23:10:29 +0000 2019'\n",
      "'Sun Oct 27 22:47:47 +0000 2019'\n",
      "'Sun Oct 27 22:47:38 +0000 2019'\n",
      "'Sun Oct 27 22:41:45 +0000 2019'\n",
      "'Sun Oct 27 22:07:13 +0000 2019'\n",
      "'Sun Oct 27 21:51:12 +0000 2019'\n",
      "'Sun Oct 27 21:40:51 +0000 2019'\n",
      "'Sun Oct 27 21:30:30 +0000 2019'\n",
      "'Sun Oct 27 21:13:38 +0000 2019'\n",
      "'Sun Oct 27 21:13:28 +0000 2019'\n",
      "'Sun Oct 27 20:55:57 +0000 2019'\n",
      "'Sun Oct 27 20:55:27 +0000 2019'\n",
      "'Sun Oct 27 20:51:48 +0000 2019'\n",
      "'Sun Oct 27 20:50:28 +0000 2019'\n",
      "'Sun Oct 27 20:47:08 +0000 2019'\n",
      "'Sun Oct 27 20:36:25 +0000 2019'\n",
      "'Sun Oct 27 20:22:15 +0000 2019'\n",
      "'Sun Oct 27 20:10:54 +0000 2019'\n",
      "'Sun Oct 27 19:27:49 +0000 2019'\n"
     ]
    }
   ],
   "source": [
    "since_id_old = 0\n",
    "while(since_id_new != since_id_old):\n",
    "    since_id_old = since_id_new\n",
    "    search_results = rest_api.search.tweets( count=count,q=q,\n",
    "                         max_id= since_id_new)\n",
    "    statuses = search_results[\"statuses\"]\n",
    "    since_id_new = statuses[-1]['id']\n",
    "    for statuse in statuses:\n",
    "        try:\n",
    "            tweet_collection.insert_one(statuse)\n",
    "            pprint(statuse['created_at']) # print the date of the collected tweets\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "182\n"
     ]
    }
   ],
   "source": [
    "print(tweet_collection.estimated_document_count())# number of tweets collected\n",
    "\n",
    "user_cursor = tweet_collection.distinct(\"user.id\")\n",
    "print (len(user_cursor)) # number of unique Twitter users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "name: Travis Kline\n",
      "text: RT @HireABearcat: *Internship Opportunity*\n",
      "Berkley is looking for a Data Analyst Intern in Urbandale, IA. Duties include demonstrating an u…\n",
      "----\n",
      "name: Hire A Bearcat\n",
      "text: *Internship Opportunity*\n",
      "Berkley is looking for a Data Analyst Intern in Urbandale, IA. Duties include demonstratin… https://t.co/zZcKOj64dO\n",
      "----\n",
      "name: Media Jobs and Internships\n",
      "text: RT @HireABearcat: Berkley Technology Services is looking for a Data Analyst Intern in Urbandale, IA. Duties include collaborating side by s…\n",
      "----\n",
      "name: TMJ-IAD Jobs\n",
      "text: Cognizant is looking for teammates like you. See our latest #BusinessMgmt job openings, including \"Data Entry Clerk… https://t.co/5WHRWYM6j0\n",
      "----\n",
      "name: Cluster IA\n",
      "text: RT @fabien_gandon: ⚠️ 👩 👨 6 post-doc job offers on Web, AI, Semantic Web, knowledge graphs, agent systems and Linked Data\n",
      "🔗 👉 https://t.co/…\n"
     ]
    }
   ],
   "source": [
    "tweet_collection.create_index([(\"text\", pymongo.TEXT)], name='text_index', default_language='english') # create a text index\n",
    "\n",
    "tweet_cursor = tweet_collection.find({\"$text\": {\"$search\": \"data mining\"}}) # return tweets contain intelligence\n",
    "for document in tweet_cursor:\n",
    "    try:\n",
    "        print ('----')\n",
    "#         pprint (document) # use pprint to print the entire tweet document\n",
    "   \n",
    "        print ('name:', document[\"user\"][\"name\"]) # user name\n",
    "        print ('text:', document[\"text\"])         # tweets\n",
    "    except:\n",
    "        print (\"***error in encoding\")\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
